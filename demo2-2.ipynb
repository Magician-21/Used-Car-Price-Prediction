{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T11:30:36.821490Z",
     "start_time": "2025-04-16T11:26:34.112360Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --------------------------\n",
    "# 缺失值填充函数\n",
    "# --------------------------\n",
    "def bodyType_fill(train, test):\n",
    "    train_value = train['bodyType'].mode()[0]\n",
    "    train['bodyType'] = train['bodyType'].fillna(train_value)\n",
    "    test['bodyType'] = test['bodyType'].fillna(train_value)\n",
    "\n",
    "def fuelType_fill(train, test):\n",
    "    train_value = train['fuelType'].mode()[0]\n",
    "    train['fuelType'] = train['fuelType'].fillna(train_value)\n",
    "    test['fuelType'] = test['fuelType'].fillna(train_value)\n",
    "\n",
    "def gearbox_fill(train, test):\n",
    "    train_value = train['gearbox'].mode()[0]\n",
    "    train['gearbox'] = train['gearbox'].fillna(train_value)\n",
    "    test['gearbox'] = test['gearbox'].fillna(train_value)\n",
    "\n",
    "def power_fill(train, test):\n",
    "    train_value = train['power'].median()\n",
    "    train['power'] = train['power'].fillna(train_value)\n",
    "    test['power'] = test['power'].fillna(train_value)\n",
    "\n",
    "def kilometer_fill(train, test):\n",
    "    train_value = train['kilometer'].mean()\n",
    "    train['kilometer'] = train['kilometer'].fillna(train_value)\n",
    "    test['kilometer'] = test['kilometer'].fillna(train_value)\n",
    "\n",
    "def notRepairedDamage_fill(train, test):\n",
    "    for df in [train, test]:\n",
    "        df['notRepairedDamage'] = df['notRepairedDamage'].replace('-', np.nan)\n",
    "        df['notRepairedDamage'] = df['notRepairedDamage'].astype('category').cat.codes\n",
    "    mode_value = train['notRepairedDamage'].mode()[0]\n",
    "    train['notRepairedDamage'] = train['notRepairedDamage'].fillna(mode_value)\n",
    "    test['notRepairedDamage'] = test['notRepairedDamage'].fillna(mode_value)\n",
    "\n",
    "# --------------------------\n",
    "# 日期处理函数\n",
    "# --------------------------\n",
    "def process_dates(df, date_col, mode_date=None):\n",
    "    date_str = df[date_col].astype(str).str.strip()\n",
    "    valid_mask = (\n",
    "        (date_str.str.len() == 8) &\n",
    "        (date_str.str.isdigit()) &\n",
    "        (date_str.str[4:6].between('01', '12')) &\n",
    "        (date_str.str[6:8].between('01', '31'))\n",
    "    )\n",
    "    dates = pd.to_datetime(\n",
    "        date_str.where(valid_mask, np.nan),\n",
    "        format='%Y%m%d',\n",
    "        errors='coerce'\n",
    "    )\n",
    "    if mode_date is not None:\n",
    "        return dates.fillna(mode_date)\n",
    "    else:\n",
    "        mode_date = dates.mode()[0] if not dates.mode().empty else pd.NaT\n",
    "        return dates.fillna(mode_date), mode_date\n",
    "\n",
    "# --------------------------\n",
    "# 主流程函数\n",
    "# --------------------------\n",
    "def load_data():\n",
    "    train = pd.read_csv('used_car_train_20200313.csv', sep=' ')\n",
    "    test = pd.read_csv('used_car_testB_20200421.csv', sep=' ')\n",
    "    return train, test\n",
    "\n",
    "def data_processing(train, test):\n",
    "    # 缺失值处理\n",
    "    notRepairedDamage_fill(train, test)\n",
    "    bodyType_fill(train, test)\n",
    "    fuelType_fill(train, test)\n",
    "    gearbox_fill(train, test)\n",
    "    power_fill(train, test)\n",
    "    kilometer_fill(train, test)\n",
    "\n",
    "    # 日期处理\n",
    "    for col in ['creatDate', 'regDate']:\n",
    "        train[col], mode_date = process_dates(train, col)\n",
    "        test[col] = process_dates(test, col, mode_date)\n",
    "\n",
    "    # 高频类别编码\n",
    "    for col in ['brand', 'regionCode']:\n",
    "        freq_map = train[col].value_counts(normalize=True)\n",
    "        train[f'{col}_freq'] = train[col].map(freq_map)\n",
    "        test[f'{col}_freq'] = test[col].map(freq_map)\n",
    "\n",
    "    # 匿名特征标准化\n",
    "    v_cols = [f'v_{i}' for i in range(15)]\n",
    "    scaler = StandardScaler()\n",
    "    train[v_cols] = scaler.fit_transform(train[v_cols])\n",
    "    test[v_cols] = scaler.transform(test[v_cols])\n",
    "\n",
    "    # 分箱处理\n",
    "    kilometer_bins = pd.cut(train['kilometer'], bins=10, retbins=True)[1]\n",
    "    train['kilometer_bin'] = pd.cut(train['kilometer'], bins=kilometer_bins, labels=False)\n",
    "    test['kilometer_bin'] = pd.cut(test['kilometer'], bins=kilometer_bins, labels=False)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"核心修正点：确保在删除日期列前完成特征衍生\"\"\"\n",
    "    if 'creatDate' in df.columns and 'regDate' in df.columns:\n",
    "        df['car_age'] = (df['creatDate'].dt.year - df['regDate'].dt.year) + \\\n",
    "                        (df['creatDate'].dt.month - df['regDate'].dt.month)/12\n",
    "\n",
    "    df['power'] = np.clip(df['power'], 0, 600)\n",
    "\n",
    "    drop_cols = ['SaleID', 'name', 'regDate', 'creatDate',\n",
    "                 'model', 'seller', 'offerType']\n",
    "    return df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "def lgb_model(train, test):\n",
    "    y_train = np.log1p(train['price'])\n",
    "    X_train = feature_engineering(train.drop(columns='price'))\n",
    "    X_test = feature_engineering(test)\n",
    "\n",
    "    params = {\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'feature_fraction': 0.8,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0,\n",
    "    'max_depth': 7,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'num_leaves': 63,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "        print(f\"Fold {fold_+1}\")\n",
    "        trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X_train.iloc[val_idx], y_train.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            trn_data,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[trn_data, val_data],\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(500)]\n",
    "        )\n",
    "        test_preds += model.predict(X_test) / folds.n_splits\n",
    "\n",
    "    return np.expm1(test_preds)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train, test = load_data()\n",
    "    train, test = data_processing(train, test)\n",
    "    predictions = lgb_model(train, test)\n",
    "    submission = pd.DataFrame({'SaleID': test['SaleID'], 'price': predictions})\n",
    "    submission.to_csv('submission.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.108228\tvalid_1's l1: 0.131592\n",
      "[1000]\ttraining's l1: 0.0919343\tvalid_1's l1: 0.129242\n",
      "Early stopping, best iteration is:\n",
      "[1316]\ttraining's l1: 0.0838057\tvalid_1's l1: 0.12848\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.108012\tvalid_1's l1: 0.130211\n",
      "[1000]\ttraining's l1: 0.0921529\tvalid_1's l1: 0.127881\n",
      "[1500]\ttraining's l1: 0.0802341\tvalid_1's l1: 0.127376\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's l1: 0.0742988\tvalid_1's l1: 0.127087\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.108427\tvalid_1's l1: 0.131246\n",
      "[1000]\ttraining's l1: 0.0921138\tvalid_1's l1: 0.128678\n",
      "[1500]\ttraining's l1: 0.0800986\tvalid_1's l1: 0.12788\n",
      "[2000]\ttraining's l1: 0.0706784\tvalid_1's l1: 0.127418\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's l1: 0.066963\tvalid_1's l1: 0.127277\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.108757\tvalid_1's l1: 0.129529\n",
      "[1000]\ttraining's l1: 0.0925626\tvalid_1's l1: 0.127358\n",
      "[1500]\ttraining's l1: 0.0804768\tvalid_1's l1: 0.12648\n",
      "[2000]\ttraining's l1: 0.0708316\tvalid_1's l1: 0.125968\n",
      "Early stopping, best iteration is:\n",
      "[2330]\ttraining's l1: 0.0655437\tvalid_1's l1: 0.125738\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.10834\tvalid_1's l1: 0.12879\n",
      "[1000]\ttraining's l1: 0.0923392\tvalid_1's l1: 0.126042\n",
      "[1500]\ttraining's l1: 0.0805713\tvalid_1's l1: 0.125123\n",
      "[2000]\ttraining's l1: 0.0710701\tvalid_1's l1: 0.124615\n",
      "Early stopping, best iteration is:\n",
      "[1972]\ttraining's l1: 0.0715485\tvalid_1's l1: 0.124573\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
