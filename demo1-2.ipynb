{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:45:26.749218Z",
     "start_time": "2025-04-16T09:32:11.800339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --------------------------\n",
    "# 缺失值填充函数\n",
    "# --------------------------\n",
    "def bodyType_fill(train, test):\n",
    "    train_value = train['bodyType'].mode()[0]\n",
    "    train['bodyType'] = train['bodyType'].fillna(train_value)\n",
    "    test['bodyType'] = test['bodyType'].fillna(train_value)\n",
    "\n",
    "def fuelType_fill(train, test):\n",
    "    train_value = train['fuelType'].mode()[0]\n",
    "    train['fuelType'] = train['fuelType'].fillna(train_value)\n",
    "    test['fuelType'] = test['fuelType'].fillna(train_value)\n",
    "\n",
    "def gearbox_fill(train, test):\n",
    "    train_value = train['gearbox'].mode()[0]\n",
    "    train['gearbox'] = train['gearbox'].fillna(train_value)\n",
    "    test['gearbox'] = test['gearbox'].fillna(train_value)\n",
    "\n",
    "def power_fill(train, test):\n",
    "    train_value = train['power'].median()\n",
    "    train['power'] = train['power'].fillna(train_value)\n",
    "    test['power'] = test['power'].fillna(train_value)\n",
    "\n",
    "def kilometer_fill(train, test):\n",
    "    train_value = train['kilometer'].mean()\n",
    "    train['kilometer'] = train['kilometer'].fillna(train_value)\n",
    "    test['kilometer'] = test['kilometer'].fillna(train_value)\n",
    "\n",
    "def notRepairedDamage_fill(train, test):\n",
    "    for df in [train, test]:\n",
    "        df['notRepairedDamage'] = df['notRepairedDamage'].replace('-', np.nan)\n",
    "        df['notRepairedDamage'] = df['notRepairedDamage'].astype('category').cat.codes\n",
    "    mode_value = train['notRepairedDamage'].mode()[0]\n",
    "    train['notRepairedDamage'] = train['notRepairedDamage'].fillna(mode_value)\n",
    "    test['notRepairedDamage'] = test['notRepairedDamage'].fillna(mode_value)\n",
    "\n",
    "# --------------------------\n",
    "# 日期处理函数\n",
    "# --------------------------\n",
    "def process_dates(df, date_col, mode_date=None):\n",
    "    date_str = df[date_col].astype(str).str.strip()\n",
    "    valid_mask = (\n",
    "        (date_str.str.len() == 8) &\n",
    "        (date_str.str.isdigit()) &\n",
    "        (date_str.str[4:6].between('01', '12')) &\n",
    "        (date_str.str[6:8].between('01', '31'))\n",
    "    )\n",
    "    dates = pd.to_datetime(\n",
    "        date_str.where(valid_mask, np.nan),\n",
    "        format='%Y%m%d',\n",
    "        errors='coerce'\n",
    "    )\n",
    "    if mode_date is not None:\n",
    "        return dates.fillna(mode_date)\n",
    "    else:\n",
    "        mode_date = dates.mode()[0] if not dates.mode().empty else pd.NaT\n",
    "        return dates.fillna(mode_date), mode_date\n",
    "\n",
    "# --------------------------\n",
    "# 主流程函数\n",
    "# --------------------------\n",
    "def load_data():\n",
    "    train = pd.read_csv('used_car_train_20200313.csv', sep=' ')\n",
    "    test = pd.read_csv('used_car_testB_20200421.csv', sep=' ')\n",
    "    return train, test\n",
    "\n",
    "def data_processing(train, test):\n",
    "    # 缺失值处理\n",
    "    notRepairedDamage_fill(train, test)\n",
    "    bodyType_fill(train, test)\n",
    "    fuelType_fill(train, test)\n",
    "    gearbox_fill(train, test)\n",
    "    power_fill(train, test)\n",
    "    kilometer_fill(train, test)\n",
    "\n",
    "    # 日期处理\n",
    "    for col in ['creatDate', 'regDate']:\n",
    "        train[col], mode_date = process_dates(train, col)\n",
    "        test[col] = process_dates(test, col, mode_date)\n",
    "\n",
    "    # 高频类别编码\n",
    "    for col in ['brand', 'regionCode']:\n",
    "        freq_map = train[col].value_counts(normalize=True)\n",
    "        train[f'{col}_freq'] = train[col].map(freq_map)\n",
    "        test[f'{col}_freq'] = test[col].map(freq_map)\n",
    "\n",
    "    # 匿名特征标准化\n",
    "    v_cols = [f'v_{i}' for i in range(15)]\n",
    "    scaler = StandardScaler()\n",
    "    train[v_cols] = scaler.fit_transform(train[v_cols])\n",
    "    test[v_cols] = scaler.transform(test[v_cols])\n",
    "\n",
    "    # 分箱处理\n",
    "    kilometer_bins = pd.cut(train['kilometer'], bins=10, retbins=True)[1]\n",
    "    train['kilometer_bin'] = pd.cut(train['kilometer'], bins=kilometer_bins, labels=False)\n",
    "    test['kilometer_bin'] = pd.cut(test['kilometer'], bins=kilometer_bins, labels=False)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"核心修正点：确保在删除日期列前完成特征衍生\"\"\"\n",
    "    if 'creatDate' in df.columns and 'regDate' in df.columns:\n",
    "        df['car_age'] = (df['creatDate'].dt.year - df['regDate'].dt.year) + \\\n",
    "                        (df['creatDate'].dt.month - df['regDate'].dt.month)/12\n",
    "\n",
    "    df['power'] = np.clip(df['power'], 0, 600)\n",
    "\n",
    "    drop_cols = ['SaleID', 'name', 'regDate', 'creatDate',\n",
    "                 'model', 'seller', 'offerType']\n",
    "    return df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "def lgb_model(train, test):\n",
    "    y_train = np.log1p(train['price'])\n",
    "    X_train = feature_engineering(train.drop(columns='price'))\n",
    "    X_test = feature_engineering(test)\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 31,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "        print(f\"Fold {fold_+1}\")\n",
    "        trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X_train.iloc[val_idx], y_train.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            trn_data,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[trn_data, val_data],\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(500)]\n",
    "        )\n",
    "        test_preds += model.predict(X_test) / folds.n_splits\n",
    "\n",
    "    return np.expm1(test_preds)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train, test = load_data()\n",
    "    train, test = data_processing(train, test)\n",
    "    predictions = lgb_model(train, test)\n",
    "    submission = pd.DataFrame({'SaleID': test['SaleID'], 'price': predictions})\n",
    "    submission.to_csv('submission.csv', index=False)"
   ],
   "id": "328d6558d58e3bb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.156474\tvalid_1's l1: 0.160842\n",
      "[1000]\ttraining's l1: 0.14106\tvalid_1's l1: 0.147847\n",
      "[1500]\ttraining's l1: 0.134384\tvalid_1's l1: 0.143192\n",
      "[2000]\ttraining's l1: 0.129577\tvalid_1's l1: 0.140266\n",
      "[2500]\ttraining's l1: 0.125639\tvalid_1's l1: 0.138002\n",
      "[3000]\ttraining's l1: 0.122298\tvalid_1's l1: 0.136342\n",
      "[3500]\ttraining's l1: 0.119374\tvalid_1's l1: 0.135041\n",
      "[4000]\ttraining's l1: 0.116793\tvalid_1's l1: 0.133969\n",
      "[4500]\ttraining's l1: 0.114517\tvalid_1's l1: 0.133137\n",
      "[5000]\ttraining's l1: 0.112351\tvalid_1's l1: 0.132397\n",
      "[5500]\ttraining's l1: 0.11037\tvalid_1's l1: 0.131747\n",
      "[6000]\ttraining's l1: 0.1085\tvalid_1's l1: 0.131196\n",
      "[6500]\ttraining's l1: 0.106758\tvalid_1's l1: 0.130676\n",
      "[7000]\ttraining's l1: 0.105079\tvalid_1's l1: 0.130191\n",
      "[7500]\ttraining's l1: 0.103435\tvalid_1's l1: 0.12973\n",
      "[8000]\ttraining's l1: 0.101838\tvalid_1's l1: 0.129221\n",
      "[8500]\ttraining's l1: 0.100303\tvalid_1's l1: 0.128689\n",
      "[9000]\ttraining's l1: 0.0988285\tvalid_1's l1: 0.128256\n",
      "[9500]\ttraining's l1: 0.097342\tvalid_1's l1: 0.12771\n",
      "[10000]\ttraining's l1: 0.0960591\tvalid_1's l1: 0.127345\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0960591\tvalid_1's l1: 0.127345\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.156915\tvalid_1's l1: 0.159894\n",
      "[1000]\ttraining's l1: 0.141453\tvalid_1's l1: 0.146824\n",
      "[1500]\ttraining's l1: 0.134898\tvalid_1's l1: 0.142316\n",
      "[2000]\ttraining's l1: 0.130141\tvalid_1's l1: 0.139441\n",
      "[2500]\ttraining's l1: 0.126071\tvalid_1's l1: 0.137032\n",
      "[3000]\ttraining's l1: 0.122778\tvalid_1's l1: 0.135288\n",
      "[3500]\ttraining's l1: 0.119749\tvalid_1's l1: 0.133778\n",
      "[4000]\ttraining's l1: 0.117156\tvalid_1's l1: 0.132627\n",
      "[4500]\ttraining's l1: 0.114763\tvalid_1's l1: 0.131651\n",
      "[5000]\ttraining's l1: 0.112622\tvalid_1's l1: 0.13084\n",
      "[5500]\ttraining's l1: 0.110668\tvalid_1's l1: 0.130244\n",
      "[6000]\ttraining's l1: 0.1088\tvalid_1's l1: 0.129596\n",
      "[6500]\ttraining's l1: 0.106986\tvalid_1's l1: 0.128971\n",
      "[7000]\ttraining's l1: 0.105312\tvalid_1's l1: 0.128451\n",
      "[7500]\ttraining's l1: 0.103707\tvalid_1's l1: 0.128007\n",
      "[8000]\ttraining's l1: 0.102123\tvalid_1's l1: 0.127524\n",
      "[8500]\ttraining's l1: 0.100611\tvalid_1's l1: 0.127109\n",
      "[9000]\ttraining's l1: 0.0991727\tvalid_1's l1: 0.126759\n",
      "[9500]\ttraining's l1: 0.0978104\tvalid_1's l1: 0.126471\n",
      "[10000]\ttraining's l1: 0.0964665\tvalid_1's l1: 0.126106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0964665\tvalid_1's l1: 0.126106\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.156715\tvalid_1's l1: 0.160194\n",
      "[1000]\ttraining's l1: 0.141543\tvalid_1's l1: 0.1473\n",
      "[1500]\ttraining's l1: 0.134904\tvalid_1's l1: 0.143056\n",
      "[2000]\ttraining's l1: 0.130125\tvalid_1's l1: 0.140355\n",
      "[2500]\ttraining's l1: 0.126059\tvalid_1's l1: 0.138186\n",
      "[3000]\ttraining's l1: 0.122633\tvalid_1's l1: 0.13646\n",
      "[3500]\ttraining's l1: 0.119664\tvalid_1's l1: 0.13514\n",
      "[4000]\ttraining's l1: 0.116979\tvalid_1's l1: 0.133999\n",
      "[4500]\ttraining's l1: 0.114644\tvalid_1's l1: 0.133105\n",
      "[5000]\ttraining's l1: 0.112469\tvalid_1's l1: 0.132293\n",
      "[5500]\ttraining's l1: 0.110559\tvalid_1's l1: 0.131697\n",
      "[6000]\ttraining's l1: 0.10872\tvalid_1's l1: 0.1312\n",
      "[6500]\ttraining's l1: 0.106937\tvalid_1's l1: 0.130607\n",
      "[7000]\ttraining's l1: 0.105336\tvalid_1's l1: 0.130166\n",
      "[7500]\ttraining's l1: 0.103755\tvalid_1's l1: 0.129743\n",
      "[8000]\ttraining's l1: 0.102251\tvalid_1's l1: 0.129339\n",
      "[8500]\ttraining's l1: 0.100802\tvalid_1's l1: 0.128939\n",
      "[9000]\ttraining's l1: 0.0994251\tvalid_1's l1: 0.128598\n",
      "[9500]\ttraining's l1: 0.098021\tvalid_1's l1: 0.128165\n",
      "[10000]\ttraining's l1: 0.0966291\tvalid_1's l1: 0.127695\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0966291\tvalid_1's l1: 0.127695\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.157161\tvalid_1's l1: 0.15926\n",
      "[1000]\ttraining's l1: 0.141732\tvalid_1's l1: 0.145876\n",
      "[1500]\ttraining's l1: 0.135172\tvalid_1's l1: 0.141276\n",
      "[2000]\ttraining's l1: 0.130458\tvalid_1's l1: 0.138226\n",
      "[2500]\ttraining's l1: 0.126632\tvalid_1's l1: 0.136118\n",
      "[3000]\ttraining's l1: 0.123464\tvalid_1's l1: 0.134596\n",
      "[3500]\ttraining's l1: 0.120645\tvalid_1's l1: 0.133341\n",
      "[4000]\ttraining's l1: 0.117932\tvalid_1's l1: 0.132182\n",
      "[4500]\ttraining's l1: 0.115511\tvalid_1's l1: 0.13129\n",
      "[5000]\ttraining's l1: 0.113289\tvalid_1's l1: 0.130472\n",
      "[5500]\ttraining's l1: 0.111287\tvalid_1's l1: 0.129845\n",
      "[6000]\ttraining's l1: 0.10936\tvalid_1's l1: 0.129173\n",
      "[6500]\ttraining's l1: 0.107593\tvalid_1's l1: 0.128586\n",
      "[7000]\ttraining's l1: 0.105887\tvalid_1's l1: 0.128066\n",
      "[7500]\ttraining's l1: 0.104264\tvalid_1's l1: 0.127584\n",
      "[8000]\ttraining's l1: 0.102667\tvalid_1's l1: 0.127057\n",
      "[8500]\ttraining's l1: 0.101194\tvalid_1's l1: 0.126618\n",
      "[9000]\ttraining's l1: 0.0997697\tvalid_1's l1: 0.126249\n",
      "[9500]\ttraining's l1: 0.0983537\tvalid_1's l1: 0.1259\n",
      "[10000]\ttraining's l1: 0.0970519\tvalid_1's l1: 0.125561\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\ttraining's l1: 0.0970535\tvalid_1's l1: 0.12556\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.157204\tvalid_1's l1: 0.158676\n",
      "[1000]\ttraining's l1: 0.141772\tvalid_1's l1: 0.145961\n",
      "[1500]\ttraining's l1: 0.135332\tvalid_1's l1: 0.141487\n",
      "[2000]\ttraining's l1: 0.130548\tvalid_1's l1: 0.138367\n",
      "[2500]\ttraining's l1: 0.126766\tvalid_1's l1: 0.136186\n",
      "[3000]\ttraining's l1: 0.123371\tvalid_1's l1: 0.134321\n",
      "[3500]\ttraining's l1: 0.120309\tvalid_1's l1: 0.132677\n",
      "[4000]\ttraining's l1: 0.117725\tvalid_1's l1: 0.131524\n",
      "[4500]\ttraining's l1: 0.115423\tvalid_1's l1: 0.130487\n",
      "[5000]\ttraining's l1: 0.113231\tvalid_1's l1: 0.129525\n",
      "[5500]\ttraining's l1: 0.111274\tvalid_1's l1: 0.128791\n",
      "[6000]\ttraining's l1: 0.109422\tvalid_1's l1: 0.128102\n",
      "[6500]\ttraining's l1: 0.107621\tvalid_1's l1: 0.127448\n",
      "[7000]\ttraining's l1: 0.105925\tvalid_1's l1: 0.126906\n",
      "[7500]\ttraining's l1: 0.104315\tvalid_1's l1: 0.126369\n",
      "[8000]\ttraining's l1: 0.102818\tvalid_1's l1: 0.125937\n",
      "[8500]\ttraining's l1: 0.101342\tvalid_1's l1: 0.125505\n",
      "[9000]\ttraining's l1: 0.0999298\tvalid_1's l1: 0.125123\n",
      "[9500]\ttraining's l1: 0.0985569\tvalid_1's l1: 0.124738\n",
      "[10000]\ttraining's l1: 0.0972259\tvalid_1's l1: 0.124356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\ttraining's l1: 0.0972272\tvalid_1's l1: 0.124356\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:25:31.969482Z",
     "start_time": "2025-04-16T10:03:53.473246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 转换为LGBMRegressor接口\n",
    "model = lgb.LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    objective='regression',\n",
    "    metric='mae',\n",
    "    learning_rate=0.01,\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'max_depth': [5, 7],\n",
    "    'min_data_in_leaf': [50, 100],\n",
    "    'feature_fraction': [0.7, 0.8],\n",
    "    'bagging_fraction': [0.8, 0.9],\n",
    "    'bagging_freq': [5],\n",
    "    'lambda_l1': [0, 0.1],\n",
    "    'lambda_l2': [0, 0.1]\n",
    "}\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "train, test = load_data()\n",
    "train, test = data_processing(train, test)\n",
    "\n",
    "y_train = np.log1p(train['price'])\n",
    "X_train = feature_engineering(train.drop(columns='price'))\n",
    "grid_search.fit(X_train, y_train)\n",
    "# 输出最优参数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score:\", -grid_search.best_score_)"
   ],
   "id": "fdf0aa93ce44ed76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\app\\Python\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 0.8, 'lambda_l1': 0.1, 'lambda_l2': 0, 'max_depth': 7, 'min_data_in_leaf': 50, 'num_leaves': 63}\n",
      "Best CV score: 0.421072461202668\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test = feature_engineering(test)\n",
    "# 使用最优参数重新训练\n",
    "best_params = grid_search.best_params_\n",
    "best_params.update({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1\n",
    "})\n",
    "\n",
    "# KFold训练与预测\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train.iloc[val_idx])\n",
    "\n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        trn_data,\n",
    "        valid_sets=[trn_data, val_data],\n",
    "        num_boost_round=10000,\n",
    "        callbacks=[lgb.early_stopping(100)]\n",
    "    )\n",
    "\n",
    "    test_preds += model.predict(X_test) / folds.n_splits\n",
    "\n",
    "submission['price'] = np.expm1(test_preds)\n",
    "submission.to_csv('tuned_submission.csv', index=False)"
   ],
   "id": "a20fff15854f07b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1316]\ttraining's l1: 0.0838057\tvalid_1's l1: 0.12848\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's l1: 0.0742988\tvalid_1's l1: 0.127087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's l1: 0.066963\tvalid_1's l1: 0.127277\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2330]\ttraining's l1: 0.0655437\tvalid_1's l1: 0.125738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1972]\ttraining's l1: 0.0715485\tvalid_1's l1: 0.124573\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
